{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder\n",
    "         .appName('ddam_project')\n",
    "         .config('spark.some.config.option','some-value')\n",
    "         .getOrCreate()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- Hotel_Address: string (nullable = true)\n",
      " |-- Additional_Number_of_Scoring: integer (nullable = true)\n",
      " |-- Review_Date: string (nullable = true)\n",
      " |-- Average_Score: double (nullable = true)\n",
      " |-- Hotel_Name: string (nullable = true)\n",
      " |-- Reviewer_Nationality: string (nullable = true)\n",
      " |-- Review_Total_Negative_Word_Counts: integer (nullable = true)\n",
      " |-- Total_Number_of_Reviews: integer (nullable = true)\n",
      " |-- Review_Total_Positive_Word_Counts: integer (nullable = true)\n",
      " |-- Total_Number_of_Reviews_Reviewer_Has_Given: integer (nullable = true)\n",
      " |-- Reviewer_Score: double (nullable = true)\n",
      " |-- Tags: string (nullable = true)\n",
      " |-- days_since_review: string (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- lng: string (nullable = true)\n",
      " |-- Review: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = spark.read.csv(\"hdfs://masterbig-1.itc.unipi.it:54310/user/student18/df_cleaned.csv\", header = True, inferSchema = True)\n",
    "df_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=14, Hotel_Address='s Gravesandestraat 55 Oost 1092 AA Amsterdam Netherlands', Additional_Number_of_Scoring=194, Review_Date='7/4/2017', Average_Score=7.7, Hotel_Name='Hotel Arena', Reviewer_Nationality='Canada', Review_Total_Negative_Word_Counts=35, Total_Number_of_Reviews=1403, Review_Total_Positive_Word_Counts=15, Total_Number_of_Reviews_Reviewer_Has_Given=1, Reviewer_Score=8.8, Tags=\"[' Leisure trip ', ' Family with young children ', ' Large King Room ', ' Stayed 5 nights ', ' Submitted from a mobile device ']\", days_since_review='30 days', lat='52.3605759', lng='4.9159683', Review='the staff in the restaurant could of been more pleasant we only visited once but that wouldn t stop us from booking again it might of just been an off night for him .  it was very good very historic building that s why I chose it'),\n",
       " Row(id=374, Hotel_Address='s Gravesandestraat 55 Oost 1092 AA Amsterdam Netherlands', Additional_Number_of_Scoring=194, Review_Date='11/3/2015', Average_Score=7.7, Hotel_Name='Hotel Arena', Reviewer_Nationality='United Kingdom', Review_Total_Negative_Word_Counts=0, Total_Number_of_Reviews=1403, Review_Total_Positive_Word_Counts=16, Total_Number_of_Reviews_Reviewer_Has_Given=2, Reviewer_Score=9.2, Tags=\"[' Leisure trip ', ' Couple ', ' Duplex Double Room ', ' Stayed 2 nights ', ' Submitted from a mobile device ']\", days_since_review='639 day', lat='52.3605759', lng='4.9159683', Review='the overall hotel was fine would love to return when the building work is complete'),\n",
       " Row(id=681, Hotel_Address='1 15 Templeton Place Earl s Court Kensington and Chelsea London SW5 9NB United Kingdom', Additional_Number_of_Scoring=244, Review_Date='10/1/2015', Average_Score=8.5, Hotel_Name='K K Hotel George', Reviewer_Nationality='United Kingdom', Review_Total_Negative_Word_Counts=6, Total_Number_of_Reviews=1831, Review_Total_Positive_Word_Counts=68, Total_Number_of_Reviews_Reviewer_Has_Given=2, Reviewer_Score=8.8, Tags=\"[' Leisure trip ', ' Couple ', ' Classic Double Room ', ' Stayed 2 nights ']\", days_since_review='672 day', lat='51.4918878', lng='-0.1949706', Review='no bad experiences at all.  there was little or nothing wrong with this excellent hotel our room was very comfortable and a good size for a london hotel it was clean tidy and well equipped the staff were first class they were polite helpful and did it all with a smile which meant a lot the breakfast menu was comprehensive and of good quality we will certainly pay a return visit')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hotel City-Nationality Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reverse_geocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3267"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check na value for lat/lng\n",
    "df_cleaned.select('lat','lng').rdd.filter(lambda x: x['lng']== 'NA').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'city': 'Cascina', 'country': 'Italy', 'country_code': 'IT'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord =[ (43.6753176,10.5408628) ]\n",
    "reverse_geocode.search(coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "df_coord = ( df_cleaned.select('id', 'lat', 'lng').rdd\n",
    "            .filter(lambda x: x['lat']!='NA' and x['lng']!='NA')\n",
    "             .map(lambda x: (x['id'], [ [float(x['lat']), float(x['lng'])] ] )) \n",
    "             .map(lambda x: (x[0], reverse_geocode.search(x[1])))\n",
    "             .map(lambda x: (x[0] , x[1][0]['city'], x[1][0]['country'], x[1][0]['country_code']))\n",
    "            ).toDF(['id','city','country','country_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(id=14, city='Amsterdam', country='Netherlands', country_code='NL'),\n",
      " Row(id=374, city='Amsterdam', country='Netherlands', country_code='NL'),\n",
      " Row(id=681, city='Kensington', country='United Kingdom', country_code='GB'),\n",
      " Row(id=860, city='Kensington', country='United Kingdom', country_code='GB'),\n",
      " Row(id=1014, city='Clerkenwell', country='United Kingdom', country_code='GB')]\n"
     ]
    }
   ],
   "source": [
    "pprint(df_coord.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|       country| count|\n",
      "+--------------+------+\n",
      "|United Kingdom|262194|\n",
      "|         Spain| 59907|\n",
      "|        France| 59514|\n",
      "|   Netherlands| 57190|\n",
      "|         Italy| 37188|\n",
      "|       Austria| 36239|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_coord.groupby('country').count().orderBy('count', ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+--------------------+-----+\n",
      "|country_code|       country|                city|count|\n",
      "+------------+--------------+--------------------+-----+\n",
      "|          GB|United Kingdom|              London|42532|\n",
      "|          GB|United Kingdom|          Kensington|36917|\n",
      "|          GB|United Kingdom|           Bayswater|33520|\n",
      "|          GB|United Kingdom|  West End of London|31523|\n",
      "|          GB|United Kingdom|      City of London|20081|\n",
      "|          GB|United Kingdom| City of Westminster|10565|\n",
      "|          GB|United Kingdom|        Canary Wharf|10238|\n",
      "|          GB|United Kingdom|            Barbican| 9897|\n",
      "|          GB|United Kingdom|             Chelsea| 9731|\n",
      "|          GB|United Kingdom|              Poplar| 9629|\n",
      "|          GB|United Kingdom|             Wembley| 6535|\n",
      "|          GB|United Kingdom|         Camden Town| 6227|\n",
      "|          GB|United Kingdom|        Belsize Park| 5173|\n",
      "|          GB|United Kingdom|         Clerkenwell| 4452|\n",
      "|          GB|United Kingdom|       Bethnal Green| 3998|\n",
      "|          GB|United Kingdom|               Acton| 3313|\n",
      "|          GB|United Kingdom|          Blackheath| 3269|\n",
      "|          GB|United Kingdom|             Lambeth| 3139|\n",
      "|          GB|United Kingdom|           Barnsbury| 3104|\n",
      "|          GB|United Kingdom|           Battersea| 2367|\n",
      "|          GB|United Kingdom|           Islington| 1567|\n",
      "|          GB|United Kingdom|             Barking| 1463|\n",
      "|          GB|United Kingdom|          Wandsworth|  586|\n",
      "|          GB|United Kingdom|           Brentford|  519|\n",
      "|          GB|United Kingdom|            Chigwell|  463|\n",
      "|          GB|United Kingdom|            Northolt|  413|\n",
      "|          GB|United Kingdom|      Buckhurst Hill|  328|\n",
      "|          GB|United Kingdom|              Morden|  260|\n",
      "|          GB|United Kingdom|           Harringay|  223|\n",
      "|          GB|United Kingdom|            Richmond|  162|\n",
      "|          ES|         Spain|         Barri Gòtic| 6322|\n",
      "|          ES|         Spain| Dreta de l'Eixample| 6321|\n",
      "|          ES|         Spain|            el Raval| 5283|\n",
      "|          ES|         Spain|            Eixample| 4533|\n",
      "|          ES|         Spain|        Ciutat Vella| 3602|\n",
      "|          ES|         Spain|Sant Pere, Santa ...| 2441|\n",
      "|          ES|         Spain|l'Antiga Esquerra...| 2430|\n",
      "|          ES|         Spain|           Barcelona| 2409|\n",
      "|          ES|         Spain|         Hostafrancs| 2284|\n",
      "|          ES|         Spain|el Parc i la Llac...| 2105|\n",
      "|          ES|         Spain|          Fort Pienc| 2041|\n",
      "|          ES|         Spain|        Diagonal Mar| 1968|\n",
      "|          ES|         Spain|la Vila Olímpica ...| 1865|\n",
      "|          ES|         Spain|el Besòs i el Mar...| 1741|\n",
      "|          ES|         Spain|          La Bordeta| 1728|\n",
      "|          ES|         Spain|      la Barceloneta| 1652|\n",
      "|          ES|         Spain|Sant Gervasi - Ga...| 1097|\n",
      "|          ES|         Spain|             el Clot| 1061|\n",
      "|          ES|         Spain|         Sant Antoni| 1037|\n",
      "|          ES|         Spain|         el Poblenou|  877|\n",
      "|          ES|         Spain|  Barri de les Corts|  795|\n",
      "|          ES|         Spain|           Les Corts|  713|\n",
      "|          ES|         Spain|la Maternitat i S...|  614|\n",
      "|          ES|         Spain|El Prat de Llobregat|  572|\n",
      "|          ES|         Spain|el Putxet i el Farró|  525|\n",
      "|          ES|         Spain|     Sagrada Família|  519|\n",
      "|          ES|         Spain|           Poble Sec|  467|\n",
      "|          ES|         Spain|        la Teixonera|  398|\n",
      "|          ES|         Spain|              Gràcia|  364|\n",
      "|          ES|         Spain|           Pedralbes|  352|\n",
      "|          ES|         Spain|la Nova Esquerra ...|  327|\n",
      "|          ES|         Spain|      Sants-Montjuïc|  293|\n",
      "|          ES|         Spain|    la Vall d'Hebron|  195|\n",
      "|          ES|         Spain|Sant Genís dels A...|  188|\n",
      "|          ES|         Spain|       Sants - Badal|  176|\n",
      "|          ES|         Spain|     Las Tres Torres|  148|\n",
      "|          ES|         Spain| Sarrià-Sant Gervasi|  130|\n",
      "|          ES|         Spain|Provenals del Pob...|  100|\n",
      "|          ES|         Spain|         La Bonanova|   93|\n",
      "|          ES|         Spain|               Sants|   91|\n",
      "|          ES|         Spain|    el Baix Guinardó|   50|\n",
      "|          NL|   Netherlands|           Amsterdam|45755|\n",
      "|          NL|   Netherlands|        Duivendrecht| 3446|\n",
      "|          NL|   Netherlands|          Amstelveen| 2599|\n",
      "|          NL|   Netherlands|             Zaandam| 2519|\n",
      "|          NL|   Netherlands|  Amsterdam-Zuidoost| 1067|\n",
      "|          NL|   Netherlands|              Diemen|  843|\n",
      "|          NL|   Netherlands|            Driemond|  506|\n",
      "|          NL|   Netherlands|            Kadoelen|  455|\n",
      "|          IT|         Italy|               Milan|30101|\n",
      "|          IT|         Italy|  Sesto San Giovanni| 2499|\n",
      "|          IT|         Italy|              Bresso| 2144|\n",
      "|          IT|         Italy|     Novate Milanese|  595|\n",
      "|          IT|         Italy|         Chiaravalle|  503|\n",
      "|          IT|         Italy|              Figino|  467|\n",
      "|          IT|         Italy|           Baranzate|  420|\n",
      "|          IT|         Italy|             Corsico|  244|\n",
      "|          IT|         Italy|              Linate|  189|\n",
      "|          IT|         Italy|    Settimo Milanese|   26|\n",
      "|          FR|        France|               Paris|30169|\n",
      "|          FR|        France|    Levallois-Perret|10100|\n",
      "|          FR|        France|              Clichy| 4879|\n",
      "|          FR|        France|              Vanves| 4336|\n",
      "|          FR|        France|          Saint-Ouen| 2858|\n",
      "|          FR|        France|           Montrouge| 2497|\n",
      "|          FR|        France|   Neuilly-sur-Seine| 1185|\n",
      "|          FR|        France|            Malakoff| 1083|\n",
      "|          FR|        France|      Ivry-sur-Seine|  688|\n",
      "|          FR|        France|  Le Kremlin-Bicêtre|  426|\n",
      "|          FR|        France| Issy-les-Moulineaux|  403|\n",
      "+------------+--------------+--------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_coord.groupby('country_code', 'country', 'city').count().orderBy('country','count',ascending = False).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_countries = df_coord.select('country').distinct().rdd.map(lambda x: x['country']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['France', 'Italy', 'Spain', 'Austria', 'United Kingdom', 'Netherlands']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estrarre la nazionalità dall'indirizzo\n",
    "def extractCountry(row):\n",
    "    for country in hotel_countries:\n",
    "        if country.lower() in row['Hotel_Address'].lower():\n",
    "            return (row['id'], country )\n",
    "    return 'EMPTY'\n",
    "        \n",
    "            \n",
    "rdd_hotel_countries = df_cleaned.select('id', 'Hotel_Address').rdd.map(extractCountry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if all reviews have an associated hotel_country \n",
    "rdd_hotel_countries.filter(lambda x: x[1] == 'EMPTY').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14, 'Netherlands')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_hotel_countries.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotel_countries = rdd_hotel_countries.toDF(['id', 'Hotel_Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=14, Hotel_Country='Netherlands'),\n",
       " Row(id=374, Hotel_Country='Netherlands'),\n",
       " Row(id=681, Hotel_Country='United Kingdom'),\n",
       " Row(id=860, Hotel_Country='United Kingdom'),\n",
       " Row(id=1014, Hotel_Country='United Kingdom'),\n",
       " Row(id=1123, Hotel_Country='United Kingdom'),\n",
       " Row(id=1162, Hotel_Country='United Kingdom'),\n",
       " Row(id=1318, Hotel_Country='United Kingdom'),\n",
       " Row(id=1375, Hotel_Country='United Kingdom'),\n",
       " Row(id=1705, Hotel_Country='United Kingdom')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hotel_countries.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.select('Reviewer_Nationality').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.select('Reviewer_Nationality').distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"Temporary table 'Reviewer_Nationality' already exists;\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/hadoopuser/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env-py3/lib/python3.4/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o36.createTempView.\n: org.apache.spark.sql.catalyst.analysis.TempTableAlreadyExistsException: Temporary table 'Reviewer_Nationality' already exists;\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.createTempView(SessionCatalog.scala:362)\n\tat org.apache.spark.sql.execution.command.CreateViewCommand.run(views.scala:154)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:87)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:87)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:185)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:64)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:2822)\n\tat org.apache.spark.sql.Dataset.createTempView(Dataset.scala:2592)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-197094d5e474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reviewer_Nationality'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/hadoopuser/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcreateTempView\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \"\"\"\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env-py3/lib/python3.4/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1286\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoopuser/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.parser.ParseException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"Temporary table 'Reviewer_Nationality' already exists;\""
     ]
    }
   ],
   "source": [
    "df_cleaned.createTempView('Reviewer_Nationality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Reviewer_Nationality='United Kingdom', N=245189),\n",
       " Row(Reviewer_Nationality='United States of America', N=35433),\n",
       " Row(Reviewer_Nationality='Australia', N=21683),\n",
       " Row(Reviewer_Nationality='Ireland', N=14821),\n",
       " Row(Reviewer_Nationality='United Arab Emirates', N=10228),\n",
       " Row(Reviewer_Nationality='Saudi Arabia', N=8947),\n",
       " Row(Reviewer_Nationality='Netherlands', N=8768),\n",
       " Row(Reviewer_Nationality='Switzerland', N=8672),\n",
       " Row(Reviewer_Nationality='Germany', N=7937),\n",
       " Row(Reviewer_Nationality='Canada', N=7893),\n",
       " Row(Reviewer_Nationality='France', N=7281),\n",
       " Row(Reviewer_Nationality='Israel', N=6609),\n",
       " Row(Reviewer_Nationality='Italy', N=6100),\n",
       " Row(Reviewer_Nationality='Belgium', N=6022),\n",
       " Row(Reviewer_Nationality='Turkey', N=5441),\n",
       " Row(Reviewer_Nationality='Kuwait', N=4917),\n",
       " Row(Reviewer_Nationality='Spain', N=4732),\n",
       " Row(Reviewer_Nationality='Romania', N=4547),\n",
       " Row(Reviewer_Nationality='Russia', N=3899),\n",
       " Row(Reviewer_Nationality='South Africa', N=3819),\n",
       " Row(Reviewer_Nationality='India', N=3436),\n",
       " Row(Reviewer_Nationality='Greece', N=3405),\n",
       " Row(Reviewer_Nationality='China', N=3399),\n",
       " Row(Reviewer_Nationality='Sweden', N=3336),\n",
       " Row(Reviewer_Nationality='New Zealand', N=3237),\n",
       " Row(Reviewer_Nationality='Singapore', N=3091),\n",
       " Row(Reviewer_Nationality='Hong Kong', N=3012),\n",
       " Row(Reviewer_Nationality='Poland', N=2887),\n",
       " Row(Reviewer_Nationality='Qatar', N=2755),\n",
       " Row(Reviewer_Nationality='Austria', N=2410),\n",
       " Row(Reviewer_Nationality='Egypt', N=2385),\n",
       " Row(Reviewer_Nationality='Norway', N=2382),\n",
       " Row(Reviewer_Nationality='Czech Republic', N=2309),\n",
       " Row(Reviewer_Nationality='Lebanon', N=2257),\n",
       " Row(Reviewer_Nationality='Hungary', N=2184),\n",
       " Row(Reviewer_Nationality='Malaysia', N=1882),\n",
       " Row(Reviewer_Nationality='Thailand', N=1879),\n",
       " Row(Reviewer_Nationality='Brazil', N=1864),\n",
       " Row(Reviewer_Nationality='Portugal', N=1835),\n",
       " Row(Reviewer_Nationality='Finland', N=1827),\n",
       " Row(Reviewer_Nationality='Denmark', N=1723),\n",
       " Row(Reviewer_Nationality='Malta', N=1684),\n",
       " Row(Reviewer_Nationality='Bahrain', N=1592),\n",
       " Row(Reviewer_Nationality='Indonesia', N=1548),\n",
       " Row(Reviewer_Nationality='Cyprus', N=1381),\n",
       " Row(Reviewer_Nationality='Luxembourg', N=1357),\n",
       " Row(Reviewer_Nationality='Croatia', N=1339),\n",
       " Row(Reviewer_Nationality='Oman', N=1332),\n",
       " Row(Reviewer_Nationality='Bulgaria', N=1314),\n",
       " Row(Reviewer_Nationality='Japan', N=1279)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT Reviewer_Nationality, COUNT(*) AS N \\\n",
    "                                                FROM Reviewer_Nationality \\\n",
    "                                                GROUP BY Reviewer_Nationality \\\n",
    "                                                ORDER BY N DESC\\\n",
    "                                                \").take(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Reviewer_Nationality='Turks Caicos Islands', count=14),\n",
       " Row(Reviewer_Nationality='Russia', count=3899),\n",
       " Row(Reviewer_Nationality='Paraguay', count=28),\n",
       " Row(Reviewer_Nationality='Anguilla', count=1),\n",
       " Row(Reviewer_Nationality='Yemen', count=16),\n",
       " Row(Reviewer_Nationality='St Maarten', count=11),\n",
       " Row(Reviewer_Nationality='Senegal', count=24),\n",
       " Row(Reviewer_Nationality='Sweden', count=3336),\n",
       " Row(Reviewer_Nationality='Kiribati', count=2),\n",
       " Row(Reviewer_Nationality='Guyana', count=5),\n",
       " Row(Reviewer_Nationality='Philippines', count=1073),\n",
       " Row(Reviewer_Nationality='Jersey', count=863),\n",
       " Row(Reviewer_Nationality='Eritrea', count=2),\n",
       " Row(Reviewer_Nationality='Djibouti', count=2),\n",
       " Row(Reviewer_Nationality='Singapore', count=3091),\n",
       " Row(Reviewer_Nationality='Malaysia', count=1882),\n",
       " Row(Reviewer_Nationality='Fiji', count=12),\n",
       " Row(Reviewer_Nationality='Turkey', count=5441),\n",
       " Row(Reviewer_Nationality='Malawi', count=10),\n",
       " Row(Reviewer_Nationality='Iraq', count=290)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.select('Reviewer_Nationality').groupby('Reviewer_Nationality').count().take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_hotel_countries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-cdf38b4500d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_nationality_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_hotel_countries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Reviewer_Nationality'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Reviewer_Score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_hotel_countries' is not defined"
     ]
    }
   ],
   "source": [
    "df_nationality_tmp = df_hotel_countries.join(df_cleaned.select('id','Reviewer_Nationality', 'Reviewer_Score'), ['id'] )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*Project [id#251L, Hotel_Country#252, Reviewer_Nationality#6, Reviewer_Score#11]\n",
      "+- *SortMergeJoin [id#251L], [id#0L], Inner\n",
      "   :- *Sort [id#251L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(id#251L, 200)\n",
      "   :     +- *Filter isnotnull(id#251L)\n",
      "   :        +- Scan ExistingRDD[id#251L,Hotel_Country#252]\n",
      "   +- *Sort [id#0L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(id#0L, 200)\n",
      "         +- *Project [id#0L, Reviewer_Nationality#6, Reviewer_Score#11]\n",
      "            +- *Filter isnotnull(id#0L)\n",
      "               +- *FileScan csv [id#0L,Reviewer_Nationality#6,Reviewer_Score#11] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://masterbig-1.itc.unipi.it:54310/user/student18/df_cleaned.csv], PartitionFilters: [], PushedFilters: [IsNotNull(id)], ReadSchema: struct<id:bigint,Reviewer_Nationality:string,Reviewer_Score:double>\n"
     ]
    }
   ],
   "source": [
    "df_nationality_tmp.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=26, Hotel_Country='Netherlands', Reviewer_Nationality='United Kingdom', Reviewer_Score=9.6, Abroad=1),\n",
       " Row(id=29, Hotel_Country='Netherlands', Reviewer_Nationality='Hungary', Reviewer_Score=9.2, Abroad=1),\n",
       " Row(id=474, Hotel_Country='United Kingdom', Reviewer_Nationality='United States of America', Reviewer_Score=6.3, Abroad=1)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding column with Abroad feature: 1 if reviewer was abroad, 0 otherwise\n",
    "\n",
    "df_abroad_temp = df_nationality_tmp.rdd.map(lambda row: (row['id'], 0 if row['Reviewer_Nationality'] == row['Hotel_Country'] else 1 )).toDF(['id','Abroad'])\n",
    "\n",
    "df_nationality = df_nationality_tmp.join(df_abroad_temp, ['id'])\n",
    "\n",
    "df_nationality.take(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178357"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nationality.rdd.filter(lambda x: x['Abroad']== 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- Hotel_Country: string (nullable = true)\n",
      " |-- Reviewer_Nationality: string (nullable = true)\n",
      " |-- Reviewer_Score: double (nullable = true)\n",
      " |-- Abroad: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_nationality.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nationality.createTempView('nationality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|Reviewer_Nationality|        AVG_SCORE|\n",
      "+--------------------+-----------------+\n",
      "|              Crimea|             10.0|\n",
      "|  Svalbard Jan Mayen|             10.0|\n",
      "|   Equatorial Guinea|             10.0|\n",
      "|             Comoros|             10.0|\n",
      "|          Cape Verde|              9.6|\n",
      "|          Tajikistan|          9.35625|\n",
      "|Central Africa Re...|              9.3|\n",
      "|        Saint Martin|            9.275|\n",
      "|              Gambia|             9.26|\n",
      "|             Burundi|9.200000000000001|\n",
      "|         South Sudan|              9.2|\n",
      "|               Benin|9.166666666666666|\n",
      "|               Congo|9.166666666666666|\n",
      "|               Niger|             9.15|\n",
      "|             Vanuatu|9.075000000000001|\n",
      "|Bonaire St Eustat...|9.066666666666666|\n",
      "|         Saint Barts|9.033333333333333|\n",
      "|          Kyrgyzstan|8.995238095238093|\n",
      "|St Pierre and Miq...|             8.95|\n",
      "|           Cocos K I|             8.95|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "df_mean_score_by_Hotel_nationality =  spark.sql(\"SELECT Reviewer_Nationality, AVG(Reviewer_Score) AS AVG_SCORE \\\n",
    "                                                FROM nationality \\\n",
    "                                                GROUP BY Reviewer_Nationality \\\n",
    "                                                ORDER BY AVG_SCORE DESC\\\n",
    "                                                \")\n",
    "df_mean_score_by_Hotel_nationality.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Table or view not found: nationality; line 1 pos 108'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/hadoopuser/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env-py3/lib/python3.4/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o23.sql.\n: org.apache.spark.sql.AnalysisException: Table or view not found: nationality; line 1 pos 108\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:459)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:478)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:463)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:61)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:61)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:60)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:58)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:58)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:331)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:329)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:58)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:58)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:58)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:331)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:329)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:58)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:463)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:453)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:85)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:82)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:82)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:74)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:74)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:62)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:50)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:63)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:592)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-478bef32cd80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_mean_score_by_Hotel_Country\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT Hotel_Country, AVG(Reviewer_Score) AS AVG_SCORE                                                 FROM nationality                                                 GROUP BY Hotel_Country                                                 ORDER BY AVG_SCORE DESC                                                \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_mean_score_by_Hotel_Country\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoopuser/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \"\"\"\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env-py3/lib/python3.4/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1286\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoopuser/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Table or view not found: nationality; line 1 pos 108'"
     ]
    }
   ],
   "source": [
    "df_mean_score_by_Hotel_Country =  spark.sql(\"SELECT Hotel_Country, AVG(Reviewer_Score) AS AVG_SCORE \\\n",
    "                                                FROM nationality \\\n",
    "                                                GROUP BY Hotel_Country \\\n",
    "                                                ORDER BY AVG_SCORE DESC\\\n",
    "                                                \")\n",
    "df_mean_score_by_Hotel_Country.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quant'è la differenza tra media aritmetica e media geografica sferica/ellissoide?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
