{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder\n",
    "         .appName('ddam_project')\n",
    "         .config('spark.some.config.option','some-value')\n",
    "         .getOrCreate()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3201f30a49ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read file from hdfs and infer schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hdfs://masterbig-1.itc.unipi.it:54310/user/student18/df_raw.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hdfs://masterbig-1.itc.unipi.it:54310/user/student18/df_cleaned.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# read file from hdfs and infer schema\n",
    "\n",
    "df_cleaned = spark.read.csv(\"hdfs://masterbig-1.itc.unipi.it:54310/user/student18/df_cleaned.csv\", header = True, inferSchema = True)\n",
    "df_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504989"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VADER evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying vader to each review and standardize score in [0,10]\n",
    "rdd_scores = (df_cleaned.select(\"Reviewer_Nationality\", \"Review\", \"Reviewer_Score\").rdd\n",
    "              #.filter(lambda row: row['Review'] is not None)\n",
    "              .map(lambda x: (x[\"Reviewer_Nationality\"], \n",
    "                              ((vader.polarity_scores(x[\"Review\"])['compound']  ) +1)*5,\n",
    "                              x[\"Reviewer_Score\"]))\n",
    "             )\n",
    "\n",
    "#.toDF([\"id\", \"Vader_scores\", \"User_scores\"])\n",
    "#df_scores.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Canada', 9.1835, 8.8),\n",
       " ('United Kingdom', 8.591999999999999, 9.2),\n",
       " ('United Kingdom', 9.8475, 8.8),\n",
       " ('United Kingdom', 5.0, 9.6),\n",
       " ('United Kingdom', 5.0, 9.2),\n",
       " ('Australia', 9.643999999999998, 10.0),\n",
       " ('United Kingdom', 3.4684999999999997, 5.0),\n",
       " ('United Kingdom', 9.907, 9.2),\n",
       " ('United Kingdom', 9.5775, 9.6),\n",
       " ('Brazil', 8.7125, 9.2)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_scores.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors(rdd, ix, iy):\n",
    "    ''' \n",
    "    rdd= rdd composed by lists/tuples \n",
    "    ix: index of the first variable\n",
    "    iy: index of the second variable\n",
    "    return: dictionary with \n",
    "    {'rmse': root mean squared error\n",
    "     'mae' : mean absolute error\n",
    "    }\n",
    "    \n",
    "    '''\n",
    "    # acc = ('counts', sum of abs errors', 'sum of squared errors')\n",
    "    acc = (0, 0, 0)\n",
    "    def mergeValue(acc, value):\n",
    "        return (acc[0] + 1, acc[1] + value,  acc[2] + value**2)\n",
    "    \n",
    "    def mergeAccum(acc1,acc2):\n",
    "        return (acc1[0] + acc2[0], acc1[1] + acc2[1], acc1[2]+acc2[2])\n",
    "    \n",
    "    acc = (rdd.map(lambda x: ( np.abs(x[ix] - x[iy]) ))\n",
    "       .aggregate(acc, mergeValue, mergeAccum)\n",
    "      )\n",
    "    \n",
    "    return {'rmse':np.sqrt(acc[2]/acc[0]) , 'mae': acc[1]/acc[0] }\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Canada', 9.1835, 8.8),\n",
       " ('United Kingdom', 8.591999999999999, 9.2),\n",
       " ('United Kingdom', 9.8475, 8.8),\n",
       " ('United Kingdom', 5.0, 9.6),\n",
       " ('United Kingdom', 5.0, 9.2),\n",
       " ('Australia', 9.643999999999998, 10.0),\n",
       " ('United Kingdom', 3.4684999999999997, 5.0),\n",
       " ('United Kingdom', 9.907, 9.2),\n",
       " ('United Kingdom', 9.5775, 9.6),\n",
       " ('Brazil', 8.7125, 9.2),\n",
       " ('Netherlands', 9.749, 8.3),\n",
       " ('United Kingdom', 9.338, 9.6),\n",
       " ('United Kingdom', 7.1075, 9.2),\n",
       " ('India', 5.0, 9.6),\n",
       " ('United Kingdom', 5.7655, 7.1),\n",
       " ('Italy', 3.9715, 7.1),\n",
       " ('United Kingdom', 9.1125, 9.6),\n",
       " ('Sweden', 8.5015, 8.3),\n",
       " ('Hong Kong', 8.8515, 7.5),\n",
       " ('United Kingdom', 2.213, 8.3)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_scores.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 1.6846593123810762, 'rmse': 2.3336413418498716}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_errors = errors(rdd_scores, 1, 2)\n",
    "vader_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nationality Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean bias correction\n",
    "first we add the mean bias of each country to the vader score  \n",
    "Correcting the score using the mean bias, the vader performance increase?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.select( \"Review\", \"Reviewer_Nationality\", \"Reviewer_Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bias_mean = spark.read.csv(\"hdfs://masterbig-1.itc.unipi.it:54310/user/student18/df_bias_mean.csv\", header = True, inferSchema = True)\n",
    "df_bias_mean = df_bias_mean.select(\"Reviewer_Nationality\", \"Bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df_cleaned.join(df_bias_mean, 'Reviewer_Nationality', 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504989\n",
      "+--------------------+--------------------+--------------+--------------------+\n",
      "|Reviewer_Nationality|              Review|Reviewer_Score|                Bias|\n",
      "+--------------------+--------------------+--------------+--------------------+\n",
      "|              Canada|staff in restaura...|           8.8|  0.1549723388282711|\n",
      "|      United Kingdom|. overall hotel w...|           9.2| 0.08905211107880007|\n",
      "|      United Kingdom|no bad experience...|           8.8| 0.08905211107880007|\n",
      "|      United Kingdom|room is small any...|           9.6| 0.08905211107880007|\n",
      "|      United Kingdom|my son and his fa...|           9.2| 0.08905211107880007|\n",
      "|           Australia|nothing to improv...|          10.0| 0.19915391522263093|\n",
      "|      United Kingdom|my and my wife ca...|           5.0| 0.08905211107880007|\n",
      "|      United Kingdom|expensive but thi...|           9.2| 0.08905211107880007|\n",
      "|      United Kingdom|nothing not to li...|           9.6| 0.08905211107880007|\n",
      "|              Brazil|. rooms are comfo...|           9.2|0.040344487213733515|\n",
      "+--------------------+--------------------+--------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_joined.count())\n",
    "df_joined.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_joined.createTempView('bias_mean')\n",
    "except:\n",
    "    spark.catalog.dropTempView('bias_mean')\n",
    "    df_joined.createTempView('bias_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|Reviewer_Nationality|count(1)|\n",
      "+--------------------+--------+\n",
      "|Turks Caicos Islands|      14|\n",
      "|            Paraguay|      28|\n",
      "|            Anguilla|       1|\n",
      "|               Yemen|      16|\n",
      "|          St Maarten|      11|\n",
      "|             Senegal|      22|\n",
      "|            Kiribati|       2|\n",
      "|              Guyana|       5|\n",
      "|             Eritrea|       2|\n",
      "|            Djibouti|       2|\n",
      "|                Fiji|      11|\n",
      "|              Malawi|      10|\n",
      "|Northern Mariana ...|       1|\n",
      "|             Comoros|       1|\n",
      "|            Cambodia|      32|\n",
      "|         Afghanistan|       7|\n",
      "|              Crimea|       6|\n",
      "|            Maldives|      47|\n",
      "|              Rwanda|      12|\n",
      "|         Ivory Coast|      19|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Reviewer_Nationality, count(*) FROM bias_mean WHERE Bias is null GROUP BY Reviewer_Nationality \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_bias(x):\n",
    "  \n",
    "    if x[\"Bias\"] == None:\n",
    "        score = (((vader.polarity_scores(x[\"Review\"])['compound']  ) +1)*5 ) + 0\n",
    "    else:\n",
    "        score = (((vader.polarity_scores(x[\"Review\"])['compound']  ) +1)*5 ) + x[\"Bias\"]\n",
    "        \n",
    "    # handling scores 'overflow'\n",
    "    if score > 10:\n",
    "        score = 10\n",
    "    elif score < 0:\n",
    "        score = 0\n",
    "        \n",
    "    return (x['Reviewer_Score'], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8.8, 9.338472338828272),\n",
       " (9.2, 8.681052111078799),\n",
       " (8.8, 9.9365521110788),\n",
       " (9.6, 5.0890521110788),\n",
       " (9.2, 5.0890521110788),\n",
       " (10.0, 9.84315391522263),\n",
       " (5.0, 3.5575521110787998),\n",
       " (9.2, 9.9960521110788),\n",
       " (9.6, 9.6665521110788),\n",
       " (9.2, 8.752844487213734),\n",
       " (8.3, 9.478764599475605),\n",
       " (9.6, 9.4270521110788),\n",
       " (9.2, 7.1965521110788),\n",
       " (9.6, 4.487335634316863),\n",
       " (7.1, 5.8545521110788),\n",
       " (7.1, 3.6853268377741637),\n",
       " (9.6, 9.2015521110788),\n",
       " (8.3, 8.277453199096339),\n",
       " (7.5, 8.482835961193082),\n",
       " (8.3, 2.3020521110788)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_bias_mean = (df_joined.rdd\n",
    "              #.filter(lambda row: row['Review'] is not None) \n",
    "              .map(vader_bias)\n",
    "             )\n",
    "rdd_bias_mean.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_errors_bias_mean = errors(rdd_bias_mean, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 1.6907125757447694, 'rmse': 2.3470459578524867}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_errors_bias_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 1.6846593123810762, 'rmse': 2.3336413418498716}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance are not improved using the mean bias correction, let's try with the median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+\n",
      "|Reviewer_Nationality|        Bias_median|     N|\n",
      "+--------------------+-------------------+------+\n",
      "|               Macau|-0.9000000000000004|   105|\n",
      "|          Azerbaijan|-0.9000000000000004|   262|\n",
      "|          Bangladesh|-0.9000000000000004|   140|\n",
      "|            Pakistan|-0.9000000000000004|   874|\n",
      "|                Iran|-0.9000000000000004|  1033|\n",
      "|               Ghana|               -0.5|   137|\n",
      "|           Hong Kong|               -0.5|  2967|\n",
      "|           Singapore|               -0.5|  3047|\n",
      "|                Oman|               -0.5|  1295|\n",
      "|                null|               -0.5|   511|\n",
      "|           Indonesia|               -0.5|  1493|\n",
      "|        Saudi Arabia|               -0.5|  8413|\n",
      "|         Switzerland|               -0.5|  8555|\n",
      "|             Belgium|               -0.5|  5918|\n",
      "|United Arab Emirates|               -0.5|  9779|\n",
      "|               Qatar|               -0.5|  2583|\n",
      "|               Kenya|               -0.5|   258|\n",
      "|             Lebanon|               -0.5|  2161|\n",
      "|            Portugal|               -0.5|  1806|\n",
      "|                Iraq|               -0.5|   258|\n",
      "|               Egypt|               -0.5|  2293|\n",
      "|               India|               -0.5|  3349|\n",
      "|          Kazakhstan|               -0.5|   269|\n",
      "|             Bahrain|               -0.5|  1523|\n",
      "|           Mauritius|               -0.5|   213|\n",
      "|              Kuwait|               -0.5|  4623|\n",
      "|             Moldova|               -0.5|   105|\n",
      "|             Nigeria|               -0.5|   934|\n",
      "|             Vietnam|               -0.5|   183|\n",
      "|               Italy|               -0.5|  5919|\n",
      "|         Netherlands|               -0.5|  8618|\n",
      "|            Malaysia|               -0.5|  1817|\n",
      "|              Norway|               -0.5|  2340|\n",
      "|              Turkey|               -0.5|  5260|\n",
      "|             Germany|               -0.5|  7822|\n",
      "|             Denmark|               -0.5|  1704|\n",
      "|              Jordan|               -0.5|   716|\n",
      "|              Monaco|               -0.5|   241|\n",
      "|           Sri Lanka|               -0.5|   277|\n",
      "|             Morocco|               -0.5|   216|\n",
      "|               Spain|-0.3000000000000007|  4611|\n",
      "|              Greece|-0.3000000000000007|  3352|\n",
      "|                Peru|                0.0|   108|\n",
      "|               Chile|                0.0|   317|\n",
      "|              Cyprus|                0.0|  1344|\n",
      "|              Latvia|                0.0|   707|\n",
      "|             Iceland|                0.0|   912|\n",
      "|             Croatia|                0.0|  1298|\n",
      "|         Isle of Man|                0.0|   395|\n",
      "|    Abkhazia Georgia|                0.0|   147|\n",
      "|           Gibraltar|                0.0|   368|\n",
      "|             Georgia|                0.0|   275|\n",
      "|           Macedonia|                0.0|   269|\n",
      "|            Slovenia|                0.0|   773|\n",
      "|             Romania|                0.0|  4430|\n",
      "|              Serbia|                0.0|  1094|\n",
      "|              Poland|                0.0|  2835|\n",
      "|           Argentina|                0.0|   499|\n",
      "|            Guernsey|                0.0|   541|\n",
      "|               China|                0.0|  3297|\n",
      "|             Belarus|                0.0|   191|\n",
      "|           Lithuania|                0.0|   722|\n",
      "|             Ireland|                0.0| 14611|\n",
      "|            Thailand|                0.0|  1804|\n",
      "|             Estonia|                0.0|   737|\n",
      "|          Montenegro|                0.0|   185|\n",
      "|             Armenia|                0.0|   125|\n",
      "|              Brazil|                0.0|  1820|\n",
      "|      Czech Republic|                0.0|  2279|\n",
      "|               Japan|                0.0|  1244|\n",
      "|          Luxembourg|                0.0|  1342|\n",
      "|             Austria|                0.0|  2365|\n",
      "|            Bulgaria|                0.0|  1279|\n",
      "|        South Africa|                0.0|  3745|\n",
      "|             Bermuda|                0.0|   101|\n",
      "|              France|                0.0|  7129|\n",
      "|              Taiwan|                0.0|   902|\n",
      "|              Jersey|                0.0|   852|\n",
      "|              Sweden|                0.0|  3297|\n",
      "|             Finland|                0.0|  1813|\n",
      "|             Albania|                0.0|   272|\n",
      "|               Malta|                0.0|  1640|\n",
      "|             Ukraine|                0.0|  1079|\n",
      "| Trinidad and Tobago|                0.0|   154|\n",
      "|Bosnia and Herzeg...|                0.0|   235|\n",
      "|            Colombia|                0.0|   263|\n",
      "|             Hungary|                0.0|  2140|\n",
      "|         Philippines|                0.0|  1050|\n",
      "|            Slovakia|                0.0|   889|\n",
      "|              Russia|                0.0|  3830|\n",
      "|              Panama| 0.3999999999999986|   117|\n",
      "|           Australia| 0.3999999999999986| 21412|\n",
      "|         South Korea| 0.3999999999999986|  1049|\n",
      "|              Israel| 0.3999999999999986|  6456|\n",
      "|              Mexico| 0.3999999999999986|   576|\n",
      "|United States of ...| 0.3999999999999986| 34887|\n",
      "|          Costa Rica| 0.3999999999999986|   118|\n",
      "|              Canada| 0.3999999999999986|  7792|\n",
      "|      United Kingdom| 0.3999999999999986|241061|\n",
      "|         New Zealand| 0.3999999999999986|  3195|\n",
      "+--------------------+-------------------+------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bias_median = spark.read.csv(\"hdfs://masterbig-1.itc.unipi.it:54310/user/student18/df_bias_median.csv\", header = True, inferSchema = True)\n",
    "df_bias_median = df_bias_median.select(\"Reviewer_Nationality\", \"Bias_median\", \"N\").orderBy('Bias_median')\n",
    "df_bias_median.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_bias_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8c65048e29de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_bias_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_bias_median\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Reviewer_Nationality'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bias_median'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_bias_mean' is not defined"
     ]
    }
   ],
   "source": [
    "df_bias = df_bias_mean.join(df_bias_median, 'Reviewer_Nationality', 'inner').orderBy('Bias_median', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at Bias (mean) vs Bias median\n",
    "df_bias.show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bias.filter(\"Reviewer_Nationality == 'Italy'\" ).collect()[0]['Bias_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_median = df_cleaned.join(df_bias_median, 'Reviewer_Nationality', 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_joined_median.createTempView('bias_median')\n",
    "except:\n",
    "    spark.catalog.dropTempView('bias_median')\n",
    "    df_joined_median.createTempView('bias_median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_bias_median(x):\n",
    "  \n",
    "    if x[\"Bias_median\"] == None:\n",
    "        score = (((vader.polarity_scores(x[\"Review\"])['compound']  ) +1)*5 ) + 0+1\n",
    "    else:\n",
    "        score = (((vader.polarity_scores(x[\"Review\"])['compound']  ) +1)*5 ) + x[\"Bias_median\"]+1\n",
    "        \n",
    "    # handling scores 'overflow'\n",
    "    if score > 10:\n",
    "        score = 10\n",
    "    elif score < 0:\n",
    "        score = 0\n",
    "        \n",
    "    return (x['Reviewer_Nationality'], x['Reviewer_Score'], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_bias_median = (df_joined_median.rdd\n",
    "              #.filter(lambda row: row['Review'] is not None) \n",
    "              .map(vader_bias_median)\n",
    "             )\n",
    "rdd_bias_median.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_errors_bias_median = errors(rdd_bias_median, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 1.4522040371175613, 'rmse': 2.0167173720720903}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_errors_bias_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 1.6590399068098154, 'rmse': 2.307100807665857}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_errors_bias_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 1.6907125757447694, 'rmse': 2.3470459578524867}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_errors_bias_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 1.6846593123810762, 'rmse': 2.3336413418498716}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le performance globali sono praticamente le stesse, solo impercettibilmente migliorate applicando il bias mediano.  \n",
    "\n",
    "Globalmente non si hanno miglioramenti significativi.  \n",
    "\n",
    "Ma, (ovviamente) le performance sui singoli paesi migliorano?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione bias su singole nazioni/hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('United States of America', 10.0, 6.399999999999999),\n",
       " ('United States of America', 8.8, 10),\n",
       " ('United States of America', 7.5, 2.8524999999999983),\n",
       " ('United States of America', 8.3, 10),\n",
       " ('United States of America', 6.3, 2.8974999999999986)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_bias_median.filter(lambda x: x[0]== 'United States of America').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 1.2088762719637625, 'rmse': 1.814910144740996}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors(rdd_bias_median.filter(lambda x: x[0]==\"United States of America\"), 1,2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 1.529733969673516, 'rmse': 2.2167606638808044}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors(rdd_scores.filter(lambda x: x[0]==\"United States of America\"), 1,2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 2.4091902226524686, 'rmse': 3.08254584146196}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors(rdd_bias_median.filter(lambda x: x[0]==\"Iran\"), 1,2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Iran', 6.7, 4.1),\n",
       " ('Iran', 8.8, 6.9594999999999985),\n",
       " ('Iran', 9.6, 8.803999999999998),\n",
       " ('Iran', 7.0, 5.320499999999999),\n",
       " ('Iran', 10.0, 4.1)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_bias_median.filter(lambda x: x[0]==\"Iran\").take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 1.9500396902226527, 'rmse': 2.581911881942934}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors(rdd_scores.filter(lambda x: x[0]==\"Iran\"), 1,2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = Statistics.colStats(rdd_scores\n",
    "                              .filter(lambda x: x['Reviewer_Nationality'=='Italy'])\n",
    "                              .map(lambda x: (x[1], x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.52036318, 8.3932562 ])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "import matplotlib.pyplot as plt\n",
    "SMALL_SIZE = 15\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y label\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "###########################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
